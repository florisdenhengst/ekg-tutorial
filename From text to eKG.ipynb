{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98cc3dfb",
   "metadata": {},
   "source": [
    "# From text to eKG\n",
    "\n",
    "This notebook has the minimum sample code to convert a transcribed interaction into is graph representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fb941d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "from random import getrandbits\n",
    "\n",
    "import requests\n",
    "from cltl.brain.long_term_memory import LongTermMemory\n",
    "from cltl.entity_linking.label_linker import LabelBasedLinker\n",
    "from cltl.triple_extraction.api import Chat\n",
    "# from cltl.triple_extraction.cfg_analyzer import CFGAnalyzer\n",
    "from cltl.triple_extraction.spacy_analyzer import spacyAnalyzer\n",
    "from cltl.triple_extraction.utils.helper_functions import utterance_to_capsules\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1a66a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "baking_scenario = [\n",
    "    \"Selene: I like baking cakes\",\n",
    "    \"Lea: I don't like cakes\",\n",
    "    \"Selene: I also like baking cookies\",\n",
    "    \"Lea: I like cookies\",\n",
    "    \"Selene: do you like chocolate cookies?\",\n",
    "    \"Lea: I love chocolate cookies\"\n",
    "    \"Selene: I will bake chocolate cookies tonight\"\n",
    "]\n",
    "baking_scenario_speakers = [\"Selene\", \"Lea\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e6e99d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context_capsule():\n",
    "    # Define contextual features\n",
    "    context_id = getrandbits(8)\n",
    "    place_id = getrandbits(8)\n",
    "    location = requests.get(\"https://ipinfo.io\").json()\n",
    "    start_date = date(2021, 3, 12)\n",
    "\n",
    "    return {\"context_id\": context_id,\n",
    "            \"date\": start_date,\n",
    "            \"place\": \"Unknown\",\n",
    "            \"place_id\": place_id,\n",
    "            \"country\": location['country'],\n",
    "            \"region\": location['region'],\n",
    "            \"city\": location['city']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "562397a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(scenario, speakers):\n",
    "    # Set logging levels\n",
    "    #     chat_logger.setLevel(logging.ERROR)\n",
    "    #     brain_logger.setLevel(logging.ERROR)\n",
    "\n",
    "    # Create analyzers\n",
    "    analyzer = spacyAnalyzer()\n",
    "    linker = LabelBasedLinker()\n",
    "\n",
    "    # Create folders\n",
    "    graph_filepath = Path('./graph/baking_graph/')\n",
    "\n",
    "    # Initialize brain, Chat, \n",
    "    brain = LongTermMemory(address=\"http://localhost:7200/repositories/sandbox\",  # Location to save accumulated graph\n",
    "                           log_dir=graph_filepath,  # Location to save step-wise graphs\n",
    "                           clear_all=True)  # To start from an empty brain\n",
    "    chat = Chat(speakers[0], speakers[-1])\n",
    "\n",
    "    # Create context\n",
    "    context_capsule = create_context_capsule()\n",
    "    brain.capsule_context(context_capsule)\n",
    "\n",
    "    all_capsules = []\n",
    "    capsules_skipped = 0\n",
    "    for turn, utterance in tqdm(enumerate(scenario)):\n",
    "        # split speaker from utterance\n",
    "        speaker, utterance = utterance.split(': ')\n",
    "        listeners = list(filter(lambda x: x != speaker, speakers))\n",
    "\n",
    "        # add utterance to chat and use spacy analyzer to analyze\n",
    "        chat.add_utterance(utterance, speaker)\n",
    "        analyzer.analyze(chat.last_utterance, speaker, listeners[0])\n",
    "        capsules = utterance_to_capsules(chat.last_utterance)\n",
    "\n",
    "        # add statement capsules to brain\n",
    "        for capsule in capsules:\n",
    "            print(capsule)\n",
    "            linker.link(capsule)\n",
    "\n",
    "            try:\n",
    "                # Add capsule to brain\n",
    "                print(\"\\tAdding capsule to brain\")\n",
    "                response = brain.capsule_statement(capsule)\n",
    "                row[key][i]['rdf_file'].append(str(response['rdf_log_path'].stem) + '.trig')\n",
    "            except:\n",
    "                capsules_skipped += 1\n",
    "                print(f\"\\tCapsule skipped. Total skipped: {capsules_skipped}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "255c57be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 22:33:55 -     INFO -                                    cltl.brain.LongTermMemory - Booted\n",
      "2023-05-25 22:33:55 -     INFO -                                    cltl.brain.LongTermMemory - Clearing brain\n",
      "2023-05-25 22:33:55 -     INFO -                                    cltl.brain.LongTermMemory - Uploading ontology to brain\n",
      "2023-05-25 22:33:56 -     INFO -                                  cltl.brain.ThoughtGenerator - Booted\n",
      "2023-05-25 22:33:56 -     INFO -                                  cltl.brain.LocationReasoner - Booted\n",
      "2023-05-25 22:33:56 -     INFO -                                      cltl.brain.TypeReasoner - Booted\n",
      "2023-05-25 22:33:56 -     INFO -                                   cltl.brain.TrustCalculator - Booted\n",
      "2023-05-25 22:33:56 -     INFO -                                  cltl.triple_extraction.Chat - << Start of Chat with Lea >>\n",
      "2023-05-25 22:33:56 -     INFO -                                    cltl.brain.LongTermMemory - Context: context200\n",
      "0it [00:00, ?it/s]2023-05-25 22:33:56 -     INFO -                                  cltl.triple_extraction.Chat - Selene     000: \"I like baking cakes\"\n",
      "2023-05-25 22:33:56 -  WARNING -                        cltl.triple_extraction.spacy_analyzer - Couldn't extract triples\n",
      "2023-05-25 22:33:56 -     INFO -                                  cltl.triple_extraction.Chat - Lea        001: \"I don't like cakes\"\n",
      "2023-05-25 22:33:56 -     INFO -                              cltl.triple_extraction.analyzer - spacyAnalyzer: Utterance type: \"STATEMENT\"\n",
      "2023-05-25 22:33:56 -     INFO -                              cltl.triple_extraction.analyzer - spacyAnalyzer: RDF triplet    subject: {\"label\": \"Lea\", \"type\": []}\n",
      "2023-05-25 22:33:56 -     INFO -                              cltl.triple_extraction.analyzer - spacyAnalyzer: RDF triplet  predicate: {\"label\": \"like\", \"type\": []}\n",
      "2023-05-25 22:33:56 -     INFO -                              cltl.triple_extraction.analyzer - spacyAnalyzer: RDF triplet     object: {\"label\": \"cake\", \"type\": []}\n",
      "1it [00:00, 24.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat': 50, 'turn': 1, 'author': 'Lea', 'utterance': \"I don't like cakes\", 'utterance_type': <UtteranceType.STATEMENT: '1'>, 'position': '0-18', 'subject': {'label': 'Lea', 'type': []}, 'predicate': {'label': 'like', 'type': []}, 'object': {'label': 'cake', 'type': []}, 'perspective': {}, 'context_id': None, 'date': '2023-05-25T22:33:56.918334', 'place': '', 'place_id': None, 'country': '', 'region': '', 'city': '', 'objects': [], 'people': []}\n",
      "{'label': 'Lea', 'type': []}\n",
      "{'label': 'cake', 'type': []}\n",
      "Lea\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbaking_scenario\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbaking_scenario_speakers\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[8], line 38\u001B[0m, in \u001B[0;36mmain\u001B[0;34m(scenario, speakers)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m capsule \u001B[38;5;129;01min\u001B[39;00m capsules:\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28mprint\u001B[39m(capsule)\n\u001B[0;32m---> 38\u001B[0m     \u001B[43mlinker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlink\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcapsule\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     41\u001B[0m         \u001B[38;5;66;03m# Add capsule to brain\u001B[39;00m\n\u001B[1;32m     42\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124mAdding capsule to brain\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/PhD/leolani/cltl-knowledgelinking/src/cltl/entity_linking/label_linker.py:20\u001B[0m, in \u001B[0;36mLabelBasedLinker.link\u001B[0;34m(self, capsule)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlink\u001B[39m(\u001B[38;5;28mself\u001B[39m, capsule):\n\u001B[0;32m---> 20\u001B[0m     capsule \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlink_entities\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcapsule\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m     capsule \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlink_predicates(capsule)\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m capsule\n",
      "File \u001B[0;32m~/Documents/PhD/leolani/cltl-knowledgelinking/src/cltl/entity_linking/label_linker.py:28\u001B[0m, in \u001B[0;36mLabelBasedLinker.link_entities\u001B[0;34m(self, capsule)\u001B[0m\n\u001B[1;32m     26\u001B[0m capsule \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_link_entity(capsule, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msubject\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     27\u001B[0m capsule \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_link_entity(capsule, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mobject\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 28\u001B[0m capsule \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_link_entity\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcapsule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mauthor\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m capsule \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_link_entity(capsule, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mitem\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m capsule\n",
      "File \u001B[0;32m~/Documents/PhD/leolani/cltl-knowledgelinking/src/cltl/entity_linking/label_linker.py:36\u001B[0m, in \u001B[0;36mLabelBasedLinker._link_entity\u001B[0;34m(self, capsule, entity_position)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_link_entity\u001B[39m(\u001B[38;5;28mself\u001B[39m, capsule, entity_position):\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28mprint\u001B[39m(capsule[entity_position])\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m entity_position \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m capsule \u001B[38;5;129;01mor\u001B[39;00m \\\n\u001B[0;32m---> 36\u001B[0m             (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muri\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[43mcapsule\u001B[49m\u001B[43m[\u001B[49m\u001B[43mentity_position\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeys\u001B[49m() \u001B[38;5;129;01mand\u001B[39;00m capsule[entity_position][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muri\u001B[39m\u001B[38;5;124m'\u001B[39m]):\n\u001B[1;32m     37\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m capsule\n\u001B[1;32m     39\u001B[0m     capsule[entity_position][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muri\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(\n\u001B[1;32m     40\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_rdf_builder\u001B[38;5;241m.\u001B[39mcreate_resource_uri(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLW\u001B[39m\u001B[38;5;124m'\u001B[39m, capsule[entity_position][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mlower()))\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'str' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "main(baking_scenario, baking_scenario_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b0c49e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ekg-tutorial",
   "language": "python",
   "name": "ekg-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
