{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98cc3dfb",
   "metadata": {},
   "source": [
    "# From text to eKG\n",
    "\n",
    "This notebook has the minimum sample code to convert a transcribed interaction into is graph representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb941d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "from random import getrandbits\n",
    "\n",
    "import requests\n",
    "from cltl.brain.long_term_memory import LongTermMemory\n",
    "from cltl.entity_linking.label_linker import LabelBasedLinker\n",
    "from cltl.triple_extraction.api import Chat\n",
    "# from cltl.triple_extraction.cfg_analyzer import CFGAnalyzer\n",
    "from cltl.triple_extraction.spacy_analyzer import spacyAnalyzer\n",
    "from cltl.triple_extraction.utils.helper_functions import utterance_to_capsules\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a66a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "baking_scenario = [\n",
    "    \"Selene: I like baking cakes\",\n",
    "    \"Lea: I don't like cakes\",\n",
    "    \"Selene: I also like baking cookies\",\n",
    "    \"Lea: I like cookies\",\n",
    "    \"Selene: do you like chocolate cookies?\",\n",
    "    \"Lea: I love chocolate cookies\"\n",
    "    \"Selene: I will bake chocolate cookies tonight\"\n",
    "]\n",
    "baking_scenario_speakers = [\"Selene\", \"Lea\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6e99d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context_capsule():\n",
    "    # Define contextual features\n",
    "    context_id = getrandbits(8)\n",
    "    place_id = getrandbits(8)\n",
    "    location = requests.get(\"https://ipinfo.io\").json()\n",
    "    start_date = date(2021, 3, 12)\n",
    "\n",
    "    return {\"context_id\": context_id,\n",
    "            \"date\": start_date,\n",
    "            \"place\": \"Unknown\",\n",
    "            \"place_id\": place_id,\n",
    "            \"country\": location['country'],\n",
    "            \"region\": location['region'],\n",
    "            \"city\": location['city']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562397a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(scenario, speakers):\n",
    "    # Set logging levels\n",
    "    #     chat_logger.setLevel(logging.ERROR)\n",
    "    #     brain_logger.setLevel(logging.ERROR)\n",
    "\n",
    "    # Create analyzers\n",
    "    analyzer = spacyAnalyzer()\n",
    "    linker = LabelBasedLinker()\n",
    "\n",
    "    # Create folders\n",
    "    graph_filepath = Path('./graph/baking_graph/')\n",
    "\n",
    "    # Initialize brain, Chat, \n",
    "    brain = LongTermMemory(address=\"http://localhost:7200/repositories/sandbox\",  # Location to save accumulated graph\n",
    "                           log_dir=graph_filepath,  # Location to save step-wise graphs\n",
    "                           clear_all=True)  # To start from an empty brain\n",
    "    chat = Chat(speakers[0], speakers[-1])\n",
    "\n",
    "    # Create context\n",
    "    context_capsule = create_context_capsule()\n",
    "    brain.capsule_context(context_capsule)\n",
    "\n",
    "    all_capsules = []\n",
    "    capsules_skipped = 0\n",
    "    for turn, utterance in tqdm(enumerate(scenario)):\n",
    "        # split speaker from utterance\n",
    "        speaker, utterance = utterance.split(': ')\n",
    "        listeners = list(filter(lambda x: x != speaker, speakers))\n",
    "\n",
    "        # add utterance to chat and use spacy analyzer to analyze\n",
    "        chat.add_utterance(utterance, speaker)\n",
    "        analyzer.analyze(chat.last_utterance, speaker, listeners[0])\n",
    "        capsules = utterance_to_capsules(chat.last_utterance)\n",
    "\n",
    "        # add statement capsules to brain\n",
    "        for capsule in capsules:\n",
    "            print(capsule)\n",
    "            linker.link(capsule)\n",
    "\n",
    "            try:\n",
    "                # Add capsule to brain\n",
    "                print(\"\\tAdding capsule to brain\")\n",
    "                response = brain.capsule_statement(capsule)\n",
    "                row[key][i]['rdf_file'].append(str(response['rdf_log_path'].stem) + '.trig')\n",
    "            except:\n",
    "                capsules_skipped += 1\n",
    "                print(f\"\\tCapsule skipped. Total skipped: {capsules_skipped}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255c57be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "main(baking_scenario, baking_scenario_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b0c49e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ekg-tutorial",
   "language": "python",
   "name": "ekg-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
